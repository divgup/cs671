{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1_q4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMFGE6BxW3SGJmGHfSzd4ki",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divgup/cs671/blob/master/assignment1_q4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxZtEO8BEnYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Activation,Dropout,Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "with h5py.File('data.h5', 'r') as file:\n",
        "    ids = pd.DataFrame(np.array(np.squeeze(file['ids'])),columns=['id'])\n",
        "    full_data = np.array(file['images']).reshape(-1,28,28,3)\n",
        "#label = pd.read_csv('label.csv')\n",
        "w_label = label['wid']\n",
        "l_label = label['len']\n",
        "c_label = label['col']\n",
        "a_label = label['ang']\n",
        "a_label = pd.get_dummies(a_label)\n",
        "#X_train,X_test,Y_train,Y1_train,Y_test,Y1_test = train_test_split(full_data,w_label,c_label,random_state=0,test_size=0.2)\n",
        "X_train,X_test,w_train,w_test,c_train,c_test,l_train,l_test,a_train,a_test = train_test_split(full_data,w_label,c_label,l_label,a_label,random_state=42,test_size=0.2)\n",
        "w_test = w_test.to_numpy()\n",
        "c_test = c_test.to_numpy()\n",
        "l_test = l_test.to_numpy()\n",
        "a_test = a_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdSvGjDEqx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(w_train.shape,c_train.shape,l_train.shape,a_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieud2cFZEuWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define seqeuntial model\n",
        "inputs = Input(shape = (28,28,3,))\n",
        "conv_1 = Conv2D(32,kernel_size=2,kernel_initializer='he_normal',input_shape=(28,28,3),activation='relu')(inputs)\n",
        "batch_n1 = BatchNormalization()(conv_1)\n",
        "drop_1 = Dropout(0.2)(batch_n1)\n",
        "conv_2 = Conv2D(64,kernel_size=3,kernel_initializer='he_normal',activation='relu')(drop_1)\n",
        "batch_n2 = BatchNormalization()(conv_2)\n",
        "max_1 = MaxPooling2D((2,2))(batch_n2)\n",
        "conv_3 = Conv2D(128,kernel_size=2,kernel_initializer='he_normal',activation='relu',padding='same')(conv_2)\n",
        "batch_n3 = BatchNormalization()(conv_3)\n",
        "max_2 = MaxPooling2D((2,2))(batch_n3)\n",
        "conv_4 = Conv2D(64,kernel_size=2,kernel_initializer='he_normal',activation='relu')(conv_3)\n",
        "batch_n4 = MaxPooling2D((2,2))(batch_n3)\n",
        "max_3 = MaxPooling2D((2,2))(batch_n4)\n",
        "drop_2 = Dropout(0.2)(max_3)\n",
        "flat_1 = Flatten()(drop_2)\n",
        "\n",
        "def angle_head():\n",
        "  angle_d1 = Dense(512,activation='relu',kernel_initializer='glorot_uniform')\n",
        "  angle_out = Dense(12,activation='softmax',name='angle_classifier')(angle_d1)\n",
        "  return angle_out\n",
        "\n",
        "def color_head():  \n",
        "  color_d1 = Dense(512,activation='relu',kernel_initializer='glorot_uniform')(flat_1)\n",
        "  color_out= Dense(1,activation='sigmoid',name='color_classifier')(color_d1)\n",
        "  return color_out\n",
        "\n",
        "def length_head():\n",
        "  l_d1 = Dense(512,activation='relu')(flat_1)\n",
        "  l_out = Dense(1,activation='sigmoid',name='length_classifier')(l_d1)\n",
        "  return l_out\n",
        "\n",
        "def width_head():\n",
        "  w_d1 = Dense(512,activation='relu')(flat_1)\n",
        "  w_out = Dense(1,activation='sigmoid',name='width_classifier')(w_d1)\n",
        "  return w_out\n",
        "\n",
        "width_h = width_head()\n",
        "color_h = color_head()\n",
        "length_h = length_head()\n",
        "angle_h = angle_head()\n",
        "\n",
        "model = Model(inputs,[w_h,color_h,length_h,angle_h])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiFy00LFE1_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_epochs = 5\n",
        "batch_size = 32\n",
        "model.compile(optimizer='Adam',loss={'width_classifier':'binary_crossentropy','color_classifier':'binary_crossentropy','length_classifier':'binary_crossentropy','angle_classifier':'categorical_crossentropy'},loss_weights={'width_classifier':1.0,'color_classifier':1.0,'length_classifier':1.0,'angle_classifier':1.0},metrics=['accuracy'])\n",
        "hist = model.fit(X_train,{'width_classifier':w_train,'color_classifier':c_train,'length_classifier':l_train,'angle_classifier':a_train},epochs = no_epochs,verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFDggq8GE5C9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_loss,w_loss,c_closs,l_loss,a_loss,w_acc,c_acc,l_acc,a_acc = model.evaluate(X_test,[w_test,c_test,l_test,a_test],verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT-Yq4p2E7zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics(confmat):\n",
        "    #confmat = confmat(true,pred)\n",
        "    sum_diag = np.sum(np.diag(confmat))\n",
        "    tot = np.sum(confmat)\n",
        "    acc = sum_diag/tot\n",
        "    precision = (np.diag(confmat))/np.sum(confmat,axis=1)\n",
        "    recall = np.diag(confmat)/np.sum(confmat,axis=0)\n",
        "    F_score = 2*precision*recall/(precision+recall)\n",
        "    return acc,precision,recall,F_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FQ9NsZkE-wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusionmatrix(true,pred):\n",
        "    num_class = np.ndarray.max(true)+1\n",
        "    confmat = [[0 for col in range(num_class)] for row in range(num_class)]\n",
        "    for i in range(true.shape[0]):\n",
        "        confmat[true[i]][pred[i]]+=1\n",
        "    return confmat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEKJZw6UFBWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test)\n",
        "pred_w = pred[0].squeeze()\n",
        "pred_c = pred[1].squeeze()\n",
        "pred_l = pred[2].squeeze()\n",
        "pred_a = pred[3].squeeze()\n",
        "test_a = np.argmax(a_test,axis=1) \n",
        "pred_w[pred_w > 0.5] = 1\n",
        "pred_w[pred_w < 0.5] = 0\n",
        "pred_c[pred_c > 0.5] = 1\n",
        "pred_c[pred_c < 0.5] = 0\n",
        "pred_l[pred_l > 0.5] = 1\n",
        "pred_l[pred_l < 0.5] = 0\n",
        "pred_a = np.argmax(pred_a,axis=1)\n",
        "pred_w = pred_w.astype('uint8')\n",
        "pred_c = pred_c.astype('uint8')\n",
        "pred_l = pred_l.astype('uint8')\n",
        "pred_a = pred_a.astype('uint8')\n",
        "#print(pred_w.shape)\n",
        "print(test_a)\n",
        "confmat_w = confusionmatrix(w_test,pred_w)\n",
        "confmat_c = confusionmatrix(c_test,pred_c)\n",
        "confmat_l = confusionmatrix(l_test,pred_l)\n",
        "confmat_a = confusionmatrix(test_a,pred_a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmXZoK4OFI1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(confmat_w)\n",
        "print(confmat_a)\n",
        "acc_w,prec_w,recall_w,f_score_w = metrics(confmat_w)\n",
        "acc_c,prec_c,recall_c,f_score_w = metrics(confmat_c)\n",
        "acc_l,prec_l,recall_l,f_score_l = metrics(confmat_l)\n",
        "acc_a,prec_a,recall_a,f_score_a = metrics(confmat_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu25Mb89FLLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_label = pred_a*1+pred_l*12+pred_c*24+pred_w*48\n",
        "true_label = test_a*1+l_test*12+c_test*24+w_test*48\n",
        "confmat = confusionmatrix(true_label,pred_label)\n",
        "#print(pred_label.shape)\n",
        "#print(confmat)\n",
        "acc,prec,recall,f_score = metrics(confmat)\n",
        "print(acc,'\\n')\n",
        "print(prec)\n",
        "#print(pred_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk0HAgyZFNiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot(epochs,hist):\n",
        "    plt.style.use('ggplot')\n",
        "    metrics=['width_classifier_loss','color_classifier_loss','length_classifier_loss','angle_classifier_loss']\n",
        "    fig,ax = plt.subplots(2,2,figsize=(20,15))\n",
        "    plt.subplots_adjust(hspace=0.2,wspace=0.2)\n",
        "    for (i,l) in enumerate(metrics):\n",
        "        title = 'Loss for {}'.format(l)\n",
        "        ax[i//2,i%2].set_title(title,fontsize=15)\n",
        "        ax[i//2,i%2].set_xlabel('Epoch',fontsize=12)\n",
        "        ax[i//2,i%2].set_ylabel('loss',fontsize=12)\n",
        "        ax[i//2,i%2].plot(np.arange(0,epochs),hist.history[l],label=l)\n",
        "plot(no_epochs,hist)\n",
        "print(hist.history)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}